{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4b30cf-4926-451a-919d-f361b241d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade classifier for face detection from the specified path\n",
    "face_cap = cv2.CascadeClassifier(\"C:/Users/yadav/AppData/Roaming/Python/Python311/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Initialize the video capture with the default camera (index 0)\n",
    "video_cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Start an infinite loop to continuously capture frames from the video source\n",
    "while True:\n",
    "    # Read a new frame from the video capture\n",
    "    ret, video_data = video_cap.read()\n",
    "    \n",
    "    # Convert the captured frame to grayscale for face detection\n",
    "    col = cv2.cvtColor(video_data, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cap.detectMultiScale(\n",
    "        col,          # Input image in grayscale\n",
    "        scaleFactor=1.1,    # Parameter specifying how much the image size is reduced at each image scale\n",
    "        minNeighbors=5,     # Parameter specifying how many neighbors each candidate rectangle should have to retain it\n",
    "        minSize=(30, 30),   # Minimum possible object size. Objects smaller than this are ignored\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE # Flag indicating the operation type for the cascade classifier\n",
    "    )\n",
    "        \n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(video_data, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the frame with rectangles around faces in a window named \"video_live\"\n",
    "    cv2.imshow(\"video_live\", video_data)\n",
    "    \n",
    "    # Break the loop if the user presses the 'a' key\n",
    "    if cv2.waitKey(10) == ord(\"a\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd5c574-5b62-4f02-8475-253588de9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# it  is  used to start the camera and recored your face\n",
    "# video_cap=cv2.VideoCapture(0)\n",
    "# while True :\n",
    "#     ret , video_data=video_cap.read()\n",
    "#     cv2.imshow(\"video_live\",video_data)\n",
    "#     if cv2.waitKey(10) == ord(\"a\") :\n",
    "#        break\n",
    "# video_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38de95-8bfc-4264-9e04-05409373d197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93ef1a-bb4d-404a-b7a0-32ef2ab57c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
